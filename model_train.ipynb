{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      "2/2 [==============================] - 1s 309ms/step - loss: 2.2906 - accuracy: 0.1250 - val_loss: 2.0864 - val_accuracy: 0.2857\n",
      "Epoch 2/55\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 1.6674 - accuracy: 0.6667 - val_loss: 1.5685 - val_accuracy: 0.4286\n",
      "Epoch 3/55\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.8042 - accuracy: 0.7917 - val_loss: 0.7893 - val_accuracy: 0.7143\n",
      "Epoch 4/55\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.2788 - accuracy: 0.9167 - val_loss: 1.5240 - val_accuracy: 0.2857\n",
      "Epoch 5/55\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0805 - accuracy: 1.0000 - val_loss: 4.0898 - val_accuracy: 0.4286\n",
      "Epoch 6/55\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.6461 - accuracy: 0.8333 - val_loss: 2.9458 - val_accuracy: 0.5714\n",
      "Epoch 7/55\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 2.4780 - val_accuracy: 0.7143\n",
      "Epoch 8/55\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.4142 - accuracy: 0.8333 - val_loss: 2.4727 - val_accuracy: 0.5714\n",
      "Epoch 9/55\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.1772 - accuracy: 0.9167 - val_loss: 1.8860 - val_accuracy: 0.7143\n",
      "Epoch 10/55\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.1295 - val_accuracy: 0.4286\n",
      "Epoch 11/55\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.5930 - val_accuracy: 0.4286\n",
      "Epoch 12/55\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 2.7070 - val_accuracy: 0.4286\n",
      "Epoch 13/55\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 2.4819 - val_accuracy: 0.4286\n",
      "Epoch 14/55\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.2622 - val_accuracy: 0.5714\n",
      "Epoch 15/55\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.1394 - val_accuracy: 0.5714\n",
      "Epoch 16/55\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.0830 - val_accuracy: 0.5714\n",
      "Epoch 17/55\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.0701 - val_accuracy: 0.4286\n",
      "Epoch 18/55\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.0807 - val_accuracy: 0.4286\n",
      "Epoch 19/55\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1001 - val_accuracy: 0.5714\n",
      "Epoch 20/55\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.1205 - val_accuracy: 0.5714\n",
      "Epoch 21/55\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1394 - val_accuracy: 0.5714\n",
      "Epoch 22/55\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.1563 - val_accuracy: 0.5714\n",
      "Epoch 23/55\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 9.9228e-04 - accuracy: 1.0000 - val_loss: 2.1699 - val_accuracy: 0.5714\n",
      "Epoch 24/55\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 7.2833e-04 - accuracy: 1.0000 - val_loss: 2.1794 - val_accuracy: 0.5714\n",
      "Epoch 25/55\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 5.9217e-04 - accuracy: 1.0000 - val_loss: 2.1841 - val_accuracy: 0.5714\n",
      "Epoch 26/55\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 4.6765e-04 - accuracy: 1.0000 - val_loss: 2.1859 - val_accuracy: 0.5714\n",
      "Epoch 27/55\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 3.8149e-04 - accuracy: 1.0000 - val_loss: 2.1844 - val_accuracy: 0.5714\n",
      "Epoch 28/55\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 3.2693e-04 - accuracy: 1.0000 - val_loss: 2.1778 - val_accuracy: 0.5714\n",
      "Epoch 29/55\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 2.5578e-04 - accuracy: 1.0000 - val_loss: 2.1710 - val_accuracy: 0.5714\n",
      "Epoch 30/55\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 2.1516e-04 - accuracy: 1.0000 - val_loss: 2.1638 - val_accuracy: 0.5714\n",
      "Epoch 31/55\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 1.8827e-04 - accuracy: 1.0000 - val_loss: 2.1563 - val_accuracy: 0.5714\n",
      "Epoch 32/55\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.5546e-04 - accuracy: 1.0000 - val_loss: 2.1497 - val_accuracy: 0.5714\n",
      "Epoch 33/55\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 1.4216e-04 - accuracy: 1.0000 - val_loss: 2.1430 - val_accuracy: 0.5714\n",
      "Epoch 34/55\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.2395e-04 - accuracy: 1.0000 - val_loss: 2.1370 - val_accuracy: 0.5714\n",
      "Epoch 35/55\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 1.1228e-04 - accuracy: 1.0000 - val_loss: 2.1310 - val_accuracy: 0.5714\n",
      "Epoch 36/55\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 1.0018e-04 - accuracy: 1.0000 - val_loss: 2.1256 - val_accuracy: 0.5714\n",
      "Epoch 37/55\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 9.0251e-05 - accuracy: 1.0000 - val_loss: 2.1203 - val_accuracy: 0.5714\n",
      "Epoch 38/55\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 8.3588e-05 - accuracy: 1.0000 - val_loss: 2.1148 - val_accuracy: 0.5714\n",
      "Epoch 39/55\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 7.6969e-05 - accuracy: 1.0000 - val_loss: 2.1097 - val_accuracy: 0.5714\n",
      "Epoch 40/55\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 7.2748e-05 - accuracy: 1.0000 - val_loss: 2.1046 - val_accuracy: 0.5714\n",
      "Epoch 41/55\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 6.7822e-05 - accuracy: 1.0000 - val_loss: 2.1002 - val_accuracy: 0.5714\n",
      "Epoch 42/55\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 6.2896e-05 - accuracy: 1.0000 - val_loss: 2.0965 - val_accuracy: 0.5714\n",
      "Epoch 43/55\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 5.9593e-05 - accuracy: 1.0000 - val_loss: 2.0931 - val_accuracy: 0.5714\n",
      "Epoch 44/55\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 5.6966e-05 - accuracy: 1.0000 - val_loss: 2.0901 - val_accuracy: 0.5714\n",
      "Epoch 45/55\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 5.3803e-05 - accuracy: 1.0000 - val_loss: 2.0877 - val_accuracy: 0.5714\n",
      "Epoch 46/55\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 5.1255e-05 - accuracy: 1.0000 - val_loss: 2.0857 - val_accuracy: 0.5714\n",
      "Epoch 47/55\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 4.9125e-05 - accuracy: 1.0000 - val_loss: 2.0841 - val_accuracy: 0.5714\n",
      "Epoch 48/55\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 4.6344e-05 - accuracy: 1.0000 - val_loss: 2.0829 - val_accuracy: 0.5714\n",
      "Epoch 49/55\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 4.4839e-05 - accuracy: 1.0000 - val_loss: 2.0817 - val_accuracy: 0.5714\n",
      "Epoch 50/55\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 4.2728e-05 - accuracy: 1.0000 - val_loss: 2.0806 - val_accuracy: 0.5714\n",
      "Epoch 51/55\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 4.1363e-05 - accuracy: 1.0000 - val_loss: 2.0798 - val_accuracy: 0.5714\n",
      "Epoch 52/55\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 3.9629e-05 - accuracy: 1.0000 - val_loss: 2.0793 - val_accuracy: 0.5714\n",
      "Epoch 53/55\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 3.8259e-05 - accuracy: 1.0000 - val_loss: 2.0788 - val_accuracy: 0.5714\n",
      "Epoch 54/55\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 3.6689e-05 - accuracy: 1.0000 - val_loss: 2.0785 - val_accuracy: 0.5714\n",
      "Epoch 55/55\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 3.5244e-05 - accuracy: 1.0000 - val_loss: 2.0784 - val_accuracy: 0.5714\n",
      "Model saved as 'handwritten_equation_model.h5'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "label_map = {\n",
    "    'equation1': 'x^2',\n",
    "    'equation2': '\\sqrt(x)',\n",
    "    'equation3': '\\sqrt[3]{x}',\n",
    "    'equation4': '\\\\ frac{x}{y}',\n",
    "    'equation5': '\\\\ frac{1}{2}',\n",
    "    'equation6': '\\ ax+b=0',\n",
    "    'equation7': '\\ ax^2+bx+c=0',\n",
    "    'equation8': '\\delta=b^2-4ac',\n",
    "    'equation9': '\\(ab)^n=a^nb^n',\n",
    "    'equation10': '(a^m)^n=a^mn',\n",
    "}\n",
    "\n",
    "# Load and preprocess the dataset with padding\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in os.listdir(data_dir):\n",
    "        label_path = os.path.join(data_dir, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            for img_file in os.listdir(label_path):\n",
    "                img_path = os.path.join(label_path, img_file)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                h, w = img.shape\n",
    "                desired_h, desired_w = 128, 128\n",
    "                \n",
    "                # If the image is smaller than the desired size, calculate padding\n",
    "                pad_h = max(0, (desired_h - h) // 2)\n",
    "                pad_w = max(0, (desired_w - w) // 2)\n",
    "\n",
    "                # Resize image to fit within desired dimensions, keeping aspect ratio\n",
    "                img_resized = cv2.resize(img, (desired_w - 2 * pad_w, desired_h - 2 * pad_h))\n",
    "                \n",
    "                # Create a blank canvas with padding\n",
    "                canvas = np.zeros((desired_h, desired_w), dtype=np.uint8)\n",
    "                canvas[pad_h:pad_h + img_resized.shape[0], pad_w:pad_w + img_resized.shape[1]] = img_resized\n",
    "\n",
    "                # Normalize\n",
    "                canvas = canvas / 255.0\n",
    "                images.append(canvas)\n",
    "                labels.append(label_map[label])\n",
    "\n",
    "    images = np.expand_dims(np.array(images), axis=-1)  # Add channel dimension\n",
    "    return images, np.array(labels)\n",
    "\n",
    "\n",
    "# Define the main function\n",
    "def main():\n",
    "    data_dir = r'C:\\Users\\Harshitha D\\OneDrive\\Desktop\\Kakracholi\\dataset\\data_prepared'  # Path to your dataset folder\n",
    "    X, y = load_data(data_dir)\n",
    "\n",
    "    # Encode the labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Build the CNN model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(128, 128, 1)),  # Updated input shape\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(len(label_map), activation='softmax')  # Output layer for number of classes\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=55, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Save the model\n",
    "    model.save('handwritten_equation_model.h5')\n",
    "    print(\"Model saved as 'handwritten_equation_model.h5'\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
